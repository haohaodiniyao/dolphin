###hadoop-2.8.1.tar.gz安装
安装博客http://blog.csdn.net/zzpzheng/article/details/73614526
#####SSH免密码登录
http://blog.csdn.net/wanglei_storage/article/details/52853034
生成秘钥对
[root@server2 ~]# ssh-keygen -t rsa
秘钥下发
[root@server2 ~]# ssh-copy-id -i /root/.ssh/id_rsa.pub root@192.168.157.129
####配置文件详解
http://www.linuxidc.com/Linux/2012-07/66286.htm
http://dongxicheng.org/mapreduce-nextgen/hadoop-yarn-configurations-resourcemanager-nodemanager/
###core-site.xml
<property>
	<name>hadoop.tmp.dir</name>
	<value>/usr/local/src/hadoop/tmp</value>
</property>
<property>
	<name>fs.defaultFS</name>
	<value>hdfs://server1:9000</value>
</property>
###hadoop-env.sh
export JAVA_HOME=/usr/local/src/jdk1.7.0_80
###hdfs-site.xml
    <property>
        <name>dfs.name.dir</name>
        <value>/usr/local/src/hadoop/dfs/name</value>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>/usr/local/src/hadoop/dfs/data</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.permissions</name>
        <value>false</value>
    </property>
###mapred-site.xml    
    <property>
        <name>mapred.job.tracker</name>
        <value>server1:49001</value>
    </property>
    <property>
        <name>mapred.local.dir</name>
        <value>/usr/local/src/hadoop/var</value>
    </property>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
###vi slaves  (其他机器没有slaves)    
server2
server3
###yarn-site.xml
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>server1</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>1024</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>1024</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
###启动###
./start-all.sh    
###访问
http://192.168.157.128:50070
http://192.168.157.128:8088/cluster
###slave机器状态
http://192.168.157.129:8042/node  




####
创建文件夹
./hadoop fs -mkdir -p /usr/local/src/input
上传文件
./hadoop fs -put /usr/local/src/sparkWordCount /usr/local/src/input